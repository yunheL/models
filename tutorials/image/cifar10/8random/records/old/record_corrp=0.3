2017-04-02 17:30:15.161724: step 0, loss = 4.68 (422.2 examples/sec; 0.303 sec/batch)
2017-04-02 17:30:19.182820: step 10, loss = 4.62 (318.3 examples/sec; 0.402 sec/batch)
2017-04-02 17:30:23.221385: step 20, loss = 4.52 (316.9 examples/sec; 0.404 sec/batch)
2017-04-02 17:30:27.235368: step 30, loss = 4.40 (318.9 examples/sec; 0.401 sec/batch)
2017-04-02 17:30:31.277644: step 40, loss = 4.37 (316.7 examples/sec; 0.404 sec/batch)
2017-04-02 17:30:35.291162: step 50, loss = 4.29 (318.9 examples/sec; 0.401 sec/batch)
2017-04-02 17:30:39.320232: step 60, loss = 4.20 (317.7 examples/sec; 0.403 sec/batch)
2017-04-02 17:30:43.364122: step 70, loss = 4.11 (316.5 examples/sec; 0.404 sec/batch)
2017-04-02 17:30:47.386391: step 80, loss = 4.29 (318.2 examples/sec; 0.402 sec/batch)
2017-04-02 17:30:51.413053: step 90, loss = 4.27 (317.9 examples/sec; 0.403 sec/batch)
2017-04-02 17:30:55.513207: step 100, loss = 4.05 (312.2 examples/sec; 0.410 sec/batch)
2017-04-02 17:30:59.514004: step 110, loss = 4.08 (319.9 examples/sec; 0.400 sec/batch)
2017-04-02 17:31:03.550406: step 120, loss = 3.99 (317.1 examples/sec; 0.404 sec/batch)
2017-04-02 17:31:07.562797: step 130, loss = 4.17 (319.0 examples/sec; 0.401 sec/batch)
2017-04-02 17:31:11.595064: step 140, loss = 4.38 (317.4 examples/sec; 0.403 sec/batch)
2017-04-02 17:31:15.635077: step 150, loss = 3.86 (316.8 examples/sec; 0.404 sec/batch)
2017-04-02 17:31:19.679111: step 160, loss = 3.80 (316.5 examples/sec; 0.404 sec/batch)
2017-04-02 17:31:23.723098: step 170, loss = 3.91 (316.5 examples/sec; 0.404 sec/batch)
2017-04-02 17:31:27.773521: step 180, loss = 3.95 (316.0 examples/sec; 0.405 sec/batch)
2017-04-02 17:31:31.839683: step 190, loss = 3.86 (314.8 examples/sec; 0.407 sec/batch)

